## 2. Существующие методы верификации центральных процессоров

Современные процессоры представляют собой чрезвычайно сложные устройства, включающие миллионы, а зачастую и миллиарды транзисторов, объединённых в сложную иерархию компонентов. Они реализуют суперскалярные и многопоточные архитектуры, глубокие конвейеры, спекулятивное исполнение, динамическое переупорядочивание инструкций, механизмы предсказания переходов, кеширования и аппаратной поддержки параллелизма. Всё это значительно увеличивает вычислительную эффективность, но также существенно расширяет пространство состояний, которое необходимо охватить в процессе верификации.

Особое внимание в последние годы уделяется архитектуре RISC-V, которая благодаря своей открытой лицензии становится всё более популярной в различных сферах — от академических исследований до промышленного производства и систем для высокопроизводительных вычислений. Открытость ISA делает RISC-V исключительно удобным для верификации: её можно формализовать, проверять, и даже адаптировать под конкретные требования, не сталкиваясь с юридическими или техническими ограничениями. Это особенно ценно для критически важных систем,  где необходим полный контроль над реализацией и её поведением системы.

// ПЕРЕПИСАТЬ -----
С другой стороны, открытая природа архитектуры также способствует модульности и расширяемости, позволяя создавать специализированные процессоры с пользовательскими расширениями — от векторных вычислений до поддержки защищённых вычислений или машинного обучения. Таким образом, RISC-V представляет собой уникальное сочетание открытости, гибкости и проверяемости, делающее его актуальным выбором для систем, где ошибка в процессоре может привести к **непредсказуемым или фатальным последствиям** — будь то встраиваемые системы в автомобилях, медицинское оборудование или бортовая электроника спутников.
// -------------------

Методы верификации процессоров, развиваемые как в академической среде, так и в индустриальных проектах, можно систематизировать в виде нескольких основных классов, различающихся по принципам и уровню абстракции:

-  **Формальная верификация (Formal Verification)** . Основана на математических методах доказательства корректности схем и архитектурных моделей. 

- **Динамическая верификация (Dynamic Verification)**. Предполагает выполнение специально подготовленных тестов на симуляторе или аппаратной модели, с последующим анализом поведения системы. 
    
- **Фаззинг (Fuzzing)**. Представляет собой метод автоматической генерации входных данных с целью провокации некорректного поведения системы. 
    
- **Рантайм верификация (Runtime Verification)**. Направлена на обнаружение ошибок, возникающих уже в произведённом чипе или в условиях его эксплуатации. 

 Каждый из этих подходов имеет свои сильные и слабые стороны, и часто они используются в комбинации. Ниже приведён более детальный обзор каждой группы методов.

### 2.1 Формальная верификация

Формальная верификация представляет собой совокупность методов, основанных на строгих математических моделях и логических рассуждениях, применяемых для доказательства корректности цифровых систем, в том числе центральных процессоров. В отличие от традиционных тестовых подходов, формальные методы не предполагают исполнение тестовой программы, а гарантируют выполнение заданных свойств путём математического доказательства.

Цель формальной верификации — показать, что схема соответствует спецификации при всех возможных входных данных и сценариях исполнения, включая граничные и редкие случаи, которые сложно охватить с помощью обычного тестирования. Основными техниками, используемых при проведении формальной верфикации CPU являются:

1. **Модельная проверка (Model Checking)**. Представляет собой автоматизированный метод анализа, при котором создаётся конечная модель поведения системы (обычно в виде конечного автомата), и затем производится проверка её соответствия заданной спецификации, формализованной, например, в языке временной логики (LTL/CTL).

2. **Доказательство теорем (Theorem Proving)**. В отличие от модельной проверки, требует ручного (или полуавтоматического) построения доказательств свойств системы. Применяются формальные языки спецификации и интерактивные доказательные системы, такие как Coq, ACL2, Isabelle/HOL, PVS. Доказательство может занимать значительное время, но позволяет анализировать более общие или бесконечные модели.

3. **Проверка эквивалентности (Equivalence Checking)**. Используется для верификации соответствия двух моделей системы — например, RTL-описания и эталонной (golden) модели на уровне архитектуры. Верификация выполняется путём сравнения логических выражений или символьного моделирования.

Несмотря на очевидные приемущества формальной верификации, такие как гарантированная полнота анализа и обнаружение ошибок на ранних этапах разработки, формальная верификация имеет ряд существенных недостатков. Основным из них является высокие требования к квалификации инженеров по верификации и сложному математическому аппарату. Так же используемое программное обеспечение для формальной верификации требует значительных капиталовложений. В дополнение к упомянотому выше, необходимо учесть затруднения в приобритении такого рода ПО и его поддержку в условиях экономических и торговых санкций. 

## 2.2 Динамическая верификация

Динамическая верификация представляет собой один из наиболее широко применяемых подходов к проверке аппаратных систем, включая центральные процессоры. В отличие от формальных методов, она основывается на наблюдении фактического поведения проектируемого устройства в ответ на заранее подготовленные входные воздействия. Исполнение тестов может производиться на различных уровнях: от симуляции RTL-кода до аппаратного прототипа или готового чипа.

Данный подход является основой промышленной практики верификации благодаря своей универсальности, хорошей интеграции в существующие проектные пайплайны и относительной простоте внедрения. Основными техниками, используемых при проведении динамической верфикации CPU являются:

 1. **Направленное тестирование (Directed Testing)**. Включает ручную разработку тестов, предназначенных для проверки конкретных аспектов работы процессора: арифметических операций, работы с памятью, прерываний, обработки исключений и т.п.
 
 2. **Случайное тестирование (Random Testing)**. Основано на автоматической генерации случайных последовательностей инструкций. Один из наиболее известных инструментов — [**riscv-dv** от Google](https://github.com/google/riscv-dv), предназначенный для генерации случайных тестов для архитектуры RISC-V с возможностью интеграции в симуляционные среды.

3. **Дифференциальное тестирование (Differential Testing)**. Метод, при котором выходные данные тестируемой реализации сравниваются с результатами эталонной модели, например, [**Spike**](https://github.com/riscv-software-src/riscv-isa-sim) или [**QEMU**](https://www.qemu.org/). Он широко используется для обнаружения отклонений в поведении, особенно в open-source реализациях процессоров.

Однако, несмотря на очевидную простоту и удобство данного метода, он **не обеспечивает полной гарантии корректности работы CPU**, поскольку охватывает лишь ограниченное множество возможных входных воздействий и состояний системы.

## 2.3 Фаззинг

Фаззинг (от англ. _fuzz testing_) — это метод автоматического тестирования, основанный на генерации большого количества входных данных с целью выявления некорректного или неожиданного поведения системы. В контексте верификации процессоров фаззинг применяется для создания нестандартных или граничных сценариев исполнения, которые трудно воспроизвести с помощью традиционного направленного тестирования. Особую ценность этот подход представляет в условиях ограниченных ресурсов или сложности применения формальных методов. 

Каждый фаззер, независимо от применяемых внутренних техник, как правило, реализует следующие этапы:

1. Генерация или выбор входных векторов.
2. Исполнения тестовых векторов на эталонной и тестируемом модели.
3. Сравнение результатов работы эталонной и тестируемой модели.
4. Оценка покрытия и вычисление фитнесс-функции.
5. Селекция и мутация входных векторов.

![[Pasted image 20250423194231.png]]
Рисунок 2.3.1 "Обощенная структура фаззинга RTL"

### 2.3.1 Методы генерации входных данных в фаззинг-верификации процессоров

Эффективность фаззинга во многом зависит от стратегии генерации входных данных. В контексте процессоров входными данными, как правило, являются исполняемые последовательности инструкций в формате заданной RISC-V ISA. Различные стратегии генерации варьируются по степени структурированности, адаптивности и вычислительной стоимости. Ниже систематизированы основные подходы, применяемые в современных системах фаззинга:

1. **Случайная генерация.** Один из наиболее простых и распространённых подходов, основанный на генерации случайных RISC-V инструкций. В этом случае тесты строятся на основе базовых синтаксических правил ISA для составления корректно-компилируемого кода на ассемблере RISC-V.

2. **Шаблонная и грамматическая генерация.** Инструкции генерируются на основе заранее определённых шаблонов, грамматик или микропрограмм, которые соответствуют специфическим поведенческим сценариям. Это обеспечивает высокий уровень семантической релевантности и позволяет направленно тестировать функциональные блоки архитектуры (например, ALU, LSU, CSR).

3. **Мутационная генерация.** Метод, предполагающий модификацию заранее подготовленных входов (seed programs) путём локальных или структурных изменений: замена инструкций, операндов, перестановка блоков и т.п. Такой подход обеспечивает управляемое разнообразие и сохраняет синтаксическую корректность.

4. Г**енерация с использованием методов машинного обучения.** Современные подходы включают использование моделей обучения с подкреплением, нейросетевых генераторов и языковых моделей. Такие системы способны адаптивно обучаться на результатах исполнения и направлять генерацию входов в наиболее «перспективные» зоны.

Анализ существующих решений демонстрирует, что наибольшую практическую ценность представляют гибридные стратегии, в которых начальные векторы, полученные с использованием грамматик или шаблонов, подвергаются последующей адаптации с помощью мутационных операторов, эволюционных алгоритмов или анализа покрытия. 

### 2.3.2 Исполнение тестовых векторов на эталонной и RTL-модели

После генерации входных данных, представляющих собой бинарные файлы програм, следующим этапом является их исполнение на двух моделях: эталонной (референсной) и тестируемой RTL-модели. Основной задачей этого этапа является получение наблюдаемых результатов исполнения, подлежащих последующему сравнению.

Эталонная модель реализует спецификацию ISA в программной форме и выступает в роли доверенного источника поведения. Такие модели имеют исчерпывающее соответствие архитектуре команд и абстрагированы от архитектурных решений. Эти модели позволяют получать детерминированные и воспроизводимые результаты исполнения, выступающие в качестве «золотого стандарта». Наиболее распространенным в среде RISC-V сообщества является эталонная модель Spike.

Тестируемая модель представляет собой реализацию процессорного ядра на уровне RTL (обычно Verilog или VHDL), предназначенную для синтеза. Её исполнение осуществляется с использованием HDL-симуляторов, таких как Verilator или VCS. В отличие от эталонной модели, RTL-дизайн включает микроархитектурные аспекты: конвейеры, буферы, кеши, предсказание переходов и прочее.

## 2.3.3 Сравнение результатов работы эталонной и тестируемой моделей

После исполнения тестового вектора на эталонной и тестируемой моделях основополагающим этапом фаззинг-тестирование является анализ полученных результатов, который заключается в выявлении результатов работы моделей. Данный процесс носит название **дифференциальной верификации** (_differential checking_) и представляет собой ключевой механизм обнаружения ошибок в реализации архитектуры процессора.

Эталонная и RTL-модель функционируют независимо друг от друга, получая в качестве входа один и тот же исполняемый файл. По завершении исполнения обе модели предоставляют некую трассировку состояний процессора во время исполнения программы. Такая трассировка отражает значения регистров(x0-x31, pc, CSR), значения памяти, флагов и другие архитектурно видимые стостояния. Однако способ проведения сравнения может варьироваться в зависимости от конкретных целей и задач верификации.

В ряде случаев используется строгое побитовое сравнение всех регистров и памяти, что позволяет с высокой точностью выявить любые отклонения от эталонного поведения. Такой подход применим, например, при анализе базовой корректности исполнения инструкций или при тестировании простых микроархитектур. В других сценариях, напротив, допустимы частичные расхождения: например, могут игнорироваться неинициализированные поля, таймеры или внутренние состояния, не влияющие на архитектурно наблюдаемое поведение. Это особенно актуально при верификации процессоров с недетерминированными компонентами, многоядерными конфигурациями или аппаратным параллелизмом.

Таким образом, вариативность в стратегии сравнения результатов исполнения эталонной и тестируемой моделей позволяет гибко адаптировать фаззинг к конкретным целям анализа. В зависимости от направления тестирования, сравнение может быть сконцентрировано на отдельных подсистемах процессора — например, регистрах общего назначения, контроллерах прерываний или механизмах управления памятью, — при этом игнорируя второстепенные микроархитектурные различия, не влияющие на архитектурно значимое поведение.

## 2.3.4 Оценка покрытия и вычисление фитнесс-функции

Одним из ключевых механизмов, обеспечивающих направленность и эффективность фаззинг-процесса, является **оценка покрытия** (_coverage analysis_) и последующее вычисление фитнес-функции (_fitness function_), которая определяет, насколько сгенерированный входной вектор (тест) способствует продвижению фаззера в пространстве состояний тестируемого устройства.​

Фитнес-функция выполняет роль целевой функции в задаче оптимизации, управляя эволюцией входных векторов и определяя, какие из них следует сохранить, мутации которых предпочтительны, и какие следует отбросить как неэффективные. На практике фаззеры применяют разнообразные метрики покрытия, отражающие глубину и разнообразие исследования архитектуры процессора. Среди них наиболее распространёнными являются:

1. Покрытие инструкций (Instruction Coverage):
$$
   C_{\text{instr}}​= \frac{∣Total ISA Instructions|}∣Executed Instructions∣​
$$   
2. Покрытие ветвлений (Branch Coverage):
$$
C_{\text{branch}} = \frac{|\text{Taken Branches}| + |\text{Not Taken Branches}|}{2 \cdot |\text{Total Branch Points}|}
$$
3. Покрытие регистров (Register State Coverage):
$$
C_{\text{reg}} = \frac{|\text{Unique Registers Congigurations}|}{ |\text{Total Branch Points}|}​
$$
4. Покрытие CSR (CSR Coverage):
   $$
C_{\text{reg}} = \frac{|\text{Touched CSR}|}{ |\text{Total Implemented CSRS}|}​
   $$
Для того чтобы направить процесс генерации тестов на выявление новых и потенциально ошибочных сценариев поведения, фаззинг-системы используют **фитнес-функции** — количественные показатели, отражающие значимость каждого теста с точки зрения достижения целей верификации. Такие функции позволяют оценить, насколько успешно конкретный входной вектор способствует, например, увеличению покрытия кода, достижению ранее неактивных архитектурных состояний или провоцированию расхождений между эталонной и тестируемой моделями.

В простейшем, в контексте фаззинг-тестирования CPU,  фитнес-функция представляет собой взвешенную сумму нескольких показателей покрытия, соответствующих тем аспектам архитектуры, которые подлежат анализу:

$$
f(x)=α⋅Cinstr​(x)+β⋅Cbranch​(x)+γ⋅D(x)
$$
где:
1. α,β,γ — весовые коэффициенты (задаются эмпирически)
2. Cinstr​(x), Cbranch(x)  — значения покрытия для данного входа
3. D(x) — дисперсия/новизна пути исполнения (например, мера отличия трассы от предыдущих).

## 2.3.5 Селекция и мутация входных векторов.

Завершающим этапом итеративного фаззинг-процесса является преобразование входных векторов, направленное на генерацию новых, потенциально более эффективных тестов. Этот процесс включает в себя селекцию (отбор на основе фитнес-функции) и мутацию (структурные изменения входных данных), что позволяет фаззеру адаптивно исследовать архитектурное пространство и последовательно приближаться к критическим состояниям.

Селекция предполагает выбор входных векторов, которые обеспечили наибольший прирост метрик покрытия или выявили расхождения между моделями. Отбор осуществляется на основе фитнес-функции и показателей дельта-покрытия.

Мутация входных данных заключается в целенаправленном изменении тестов с целью генерации новых программ, при этом сохраняется синтаксическая и/или семантическая валидность инструкций. Ниже приведены способы измения тестовых последовательностей:

- **Битовые мутации** — случайная инверсия или сдвиг отдельных битов в коде инструкции.
```
						MOV x5, x6→MOV x5
```
    
- **Семантические мутации** — замена инструкции на функционально схожую:
```
						ADD -> SUB; LOAD-> STORE;
```
    
- **Мутации на уровне блоков** — перестановка, дублирование или удаление базовых блоков, циклов или подпрограмм.

## 2.3.6 Заключение по теоретической части.

Несмотря на разнообразие применяемых реализаций и конкретных технических решений, большинство фаззинг-систем, предназначенных для верификации процессорных архитектур, следуют унифицированной многоэтапной структуре, включающей пять ключевых компонентов: генерацию тестов, их исполнение, сравнение результатов, анализ метрик покрытия и эволюционное преобразование входных данных.

Каждый из этих этапов, являясь функционально независимым, может быть адаптирован в соответствии с целями и масштабом верификации. Например, на этапе генерации можно использовать как случайные, так и формально-направленные методы; на этапе исполнения — применять различную степень точности моделей; сравнение может быть строгим или контекстно-зависимым; фитнес-функция — однофакторной или сложной композитной; а мутация — как статической, так и адаптивной во времени.

Именно гибкость на уровне каждого этапа позволяет фаззингу быть масштабируемым и универсальным инструментом, применимым к архитектурам различной сложности — от простейших микроконтроллеров до многоядерных процессоров общего назначения и специализированных вычислительных ускорителей. Благодаря модульной природе, фаззинг-системы легко интегрируются в существующие верификационные пайплайны и могут быть переориентированы на проверку конкретных аспектов поведения системы: будь то ISA-соответствие, исследование исключительных ситуаций или стресс-тестирование взаимодействия подсистем.

Таким образом, фаззинг как метод обеспечивает не только автоматизированный, но и адаптивный процесс верификации, где качество анализа определяется не столько глубиной отдельного этапа, сколько согласованной настройкой и целенаправленным взаимодействием всех компонентов. Это делает фаззинг особенно перспективным направлением в области анализа аппаратных архитектур с растущей сложностью и требованиями к верификационной полноте.