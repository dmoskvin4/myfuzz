# 3. Генетические алгоритмы

**Генетические алгоритмы (ГА)** представляют собой класс стохастических методов оптимизации, основанных на принципах естественного отбора и наследования, заимствованных из теории эволюции. Будучи частью более широкой области **эволюционных вычислений**, генетические алгоритмы находят широкое применение в задачах, где традиционные методы оптимизации оказываются неэффективными или неприменимыми — особенно в условиях высокого уровня неопределённости, большого пространства поиска и отсутствия аналитической модели.

В контексте современной вычислительной техники ГА часто рассматриваются как **эвристические методы машинного обучения**, так как они реализуют процесс адаптации через итеративное улучшение популяции решений на основе оценки их качества (фитнеса). В отличие от традиционных алгоритмов обучения с учителем, генетические алгоритмы не требуют размеченных данных и работают по принципу «поиска через выживание лучших».

ГА являются мощным инструментом при решении задач, где необходимо находить приближённые или субоптимальные решения, особенно в системах с ограниченной наблюдаемостью и высокой вычислительной сложностью. Это делает их привлекательными в таких областях, как автоматизированное тестирование, фаззинг, настройка систем, проектирование архитектур и оптимизация сложных систем. Ниже представлены основные этапы классического ГА:

1. Инциализация популяции
2. Оценка приспособленности
3. Селекция (отбор)
4. Кроссовер (скрещивание)
5. Мутация
6. Замена покалений

Опишем несколько подробнее каждый из шагов работы генетического алгоритма.

## 3.1 Инициализация популяции

Инициализация популяции является первым и критически важным этапом генетического алгоритма, определяющим исходное распределение решений в пространстве поиска. От качества начальной популяции во многом зависит скорость сходимости алгоритма, его способность избегать локальных минимумов и общая эффективность поиска.

В рамках ГА под популяцией понимается множество:
$$
P_0 = \{x_1, x_2, \dots, x_N\}
$$
где каждый элемент x - потенциальное решение задачи, закодированное в виде **хромосомы**. Формат хромосомы определяется спецификой задачи: это может быть вектор, целочисленная последовательность, структура данных, или даже программа (в случае применений в фаззинге процессора).

На практике инициализация популяции может осуществляться следующими способами:

- **Случайная генерация** — наиболее универсальный и широко применяемый подход, при котором особи создаются путём равномерного или распределённого выбора параметров в пределах допустимого пространства X. Такой метод обеспечивает высокую диверсификацию популяции, но может порождать некорректные или неэффективные с точки зрения целевой функции решения.

- **Семантически-направленная инициализация** — применяется, когда доступна априорная информация о структуре хороших решений. Например, в случае фаззинг-тестирования процессоров могут использоваться валидные программы, генерируемые инструментами типа `riscv-dv`, либо специально разработанные шаблоны инструкций, активирующие определённые подсистемы.

- **Гибридные методы** — комбинируют случайную генерацию с добавлением заранее известных тестов, что особенно эффективно в задачах, где пространственная плотность полезных решений невелика.

На практике успешная инициализация популяции требует учёта ряда инженерных ограничений, связанных как с корректностью формируемых решений, так и с эффективностью их дальнейшего использования в процессе оптимизации. Поэтому при формировании первой популяции для работы генетического алгоритма нужно учесть:

1. Контроль корректности особей на этапе генерации. Начальные вектора должны быть синтаксически корректны для RISC-V ассемблера.
2. Ограничение размерности или сложности хромосом. Снижает вычислительную нагрузку и способствует стабильной и быстрой сходимости генетического алгоритма.

## 3.2 Оценка приспособленности

Оценка приспособленности особей в популяции представляет собой механизм введения направленного давления отбора, которое систематически смещает поиск решений в сторону областей пространства, обладающих наилучшими характеристиками в контексте целевой задачи. Фитнес-функция служит не только критерием качества, но и определяет форму фитнес-ландшафта, по которому алгоритм осуществляет поиск.

В зависимости от специфики задачи фитнес-функции могут быть:

- **одноцелевыми** — отражать только одну метрику;
- **многоцелевыми** — учитывать несколько критериев одновременно (например, покрытие + глубина состояния + ресурсные ограничения);
- **с динамическими целями** — адаптировать приоритеты в зависимости от стадии поиска.

Пример многоцелевой фитнес-функции:
$$
f(x)=α⋅Cinstr(x)+β⋅E(x)−γ⋅R(x)f(x) = \alpha \cdot C_{\text{instr}}(x) + \beta \cdot E(x) - \gamma \cdot R(x)f(x)=α⋅Cinstr​(x)+β⋅E(x)−γ⋅R(x)
$$
- Cinstr(x) — степень покрытия инструкций;
- E(x) — обнаруженные ошибки (events);
- R(x) -время исполнения;
- α,β,γ — настраиваемые веса.

Фитнес-функция в генетических алгоритмах играет роль не только измерителя качества решений, но и активного управляющего механизма, формирующего динамику эволюционного процесса. Композиция фитнес-функций, нормализация их значений и адаптация критериев качества являются важнейшими средствами повышения эффективности поиска оптимальных решений в сложных пространствах.

## 3.3 Селекция

Селекция (или отбор) — это механизм в генетическом алгоритме, реализующий принцип естественного отбора: особи, обладающие более высокой приспособленностью, имеют больше шансов быть отобранными для участия в формировании следующего поколения. Основная цель селекции — обеспечить направленное распространение «успешных признаков» и ускорить сходимость алгоритма к оптимальному или субоптимальному решению.

В то же время, чрезмерно сильное селекционное давление может привести к  потере генетического разнообразия, что снижает эффективность поиска. Поэтому выбор метода селекции и его параметров оказывает значительное влияние на поведение алгоритма.

Пусть имеется популяция вида
$$
P_t = \{x_1, x_2, \dots, x_N\}
$$

1. **Рулетка.** Каждая особь получает шанс быть отобранной пропорционально своему значению фитнес-функции. Вероятность выбора особи xi определяется как:
$$
p_i = \frac{f(x_i)}{\sum\limits_{j=1}^{N} f(x_j)}
$$
2. **Тунирная селекция.** Из популяции случайно выбирается группа из k особей, и из них побеждает лучшая. Повторяется до нужного размера. При k -> N отбор становится более жестким, нежели чем при k = 2.
3. **Ранговая селекция.** Сначала популяция сортируется по значению фитнеса, затем каждой особи присваивается вероятность отбора в зависимости от её ранга, а не абсолютного значения функции селекции. Это снижает влияние фитнес-доминирования и сохраняет разнообразие.
4. **Элитизм.** Независимо от метода отбора, e лучших особей (по значению фитнес-функции) переносятся в следующее поколение без изменений. Это гарантирует сохранение лучших решений.

Несмотря на разнообразие методов селекции, ни один из них не является универсально оптимальным для всех классов задач. В реальных инженерных системах, включая задачи автоматизированного тестирования и фаззинг-ориентированной верификации, часто применяются **комбинированные стратегии селекции**, сочетающие преимущества различных подходов. Например, турнирная селекция может быть дополнена элементами элитизма. Такая гибридизация позволяет более точно настраивать селекционное давление, поддерживать генетическое разнообразие популяции и адаптировать поведение алгоритма к конкретной проблемной области.

## 3.4. Скрещивание (кроссовер)

Кроссовер (или скрещивание) представляет собой оператор, моделирующий процесс наследования признаков между двумя родительскими особями, с целью получения одного или нескольких потомков, потенциально сочетающих полезные характеристики обоих родителей. Это ключевой источник **комбинаторного разнообразия** в генетических алгоритмах, позволяющий ускорить исследование пространства решений и выход за пределы локальных экстремумов.

Применение кроссовера направлено на **рекомбинацию** высокоадаптивных фрагментов хромосом, выявленных в процессе отбора. В отличие от мутации, которая вводит случайные изменения, кроссовер ориентирован на структурированное переиспользование успешных решений. Ниже перечислены основные типы кроссовера:

1. Одноточечный кроссовер. Выбирается случайная точка разреза, и родительские хромосомы обмениваются своими частями.
```
Родитель A: [A1 | A2 A3 A4]  
Родитель B: [B1 | B2 B3 B4]  
Потомок:    [A1 | B2 B3 B4]
```

2. Униформный кроссовер. Каждый ген потомка выбирается независимо от одного из родителей с вероятностью 0.5 (или иным заданным распределением).
```
Родитель A: [1 0 0 1 1]  
Родитель B: [0 1 1 0 0]  
Потомок:    [1 1 0 1 0]
```

3. Семантически-осознанный кроссовер. Используется в задачах, где хромосома представляет структурированные объекты — например, программы или инструкции. В этом случае кроссовер может происходить по границам базовых блоков, циклов или функций, обеспечивая логическую целостность потомка, хотя и требует сложной реализации и анализа семантики.

Кроссовер выполняет важную функцию в процессе эволюции, обеспечивая комбинирование и распространение адаптивных признаков между особями. Разумный выбор схемы и частоты применения кроссовера, а также учёт структуры решения позволяют эффективно использовать этот оператор в рамках общего эволюционного процесса и повышать вероятность нахождения качественных решений в сложных пространствах поиска.

## 3.5 Мутация

Мутация представляет собой оператор случайного изменения хромосомы, направленный на введение новых генетических вариаций в популяцию. Основная функция мутации — поддержание генетического разнообразия, предотвращение преждевременной сходимости и обеспечение способности алгоритма исследовать ранее неохваченные области пространства решений.

В отличие от кроссовера, мутация действует на уровне одной особи и не зависит от других членов популяции. Это делает её особенно ценной в тех случаях, когда популяция уже начала вырождаться или скрещивание не приносит существенного прироста в качестве решений.

Ниже перечислены типовые виды мутаций, применяемые в фаззинг-системах уровня CPU:

1. Замена инструкции. Одна инструкция заменяется на другую из той же категории:
```
ADD x1, x2, x3  →  SUB x1, x2, x3
LW x4, 0(x5)    →  SW x4, 0(x5)
```
2. Изменение операндов. Мутация одного или нескольких операндов. Например, замена регистра с x3  на x7.
3. Вставка инструкций (часто из пула разрешённых):
```
addi x1, x0, 5             addi x1, x0, 5
addi x2, x0, 10    ->      addi x2, x0, 10
add  x3, x1, x2            slli x2, x2, 1
                           add  x3, x1, x2
```
3. Удаление произвольной инструкции (обратно вставке инструкции).
4. Мутации на уровне базовых блоков:
```
_L1 → _L2 → _L3     →     _L3 → L2 → _L1
```
Операторы мутации в генетических алгоритмах представляют собой мощный инструмент для расширения пространства поиска и преодоления локальных оптимумов. Их высокая гибкость позволяет реализовывать как простые случайные изменения, так и сложные контекстно-зависимые преобразования, направленные на структурную модификацию решения.

Однако при применении мутаций в задачах фаззинг-тестирования процессоров, в частности архитектуры RISC-V, необходимо учитывать ряд критических факторов: синтаксическую и семантическую корректность генерируемых инструкций, допустимость взаимодействия с архитектурными регистрами, а также влияние отдельных мутаций на траекторию исполнения теста. Использование необоснованных или неконтролируемых мутаций может привести к невалидным или тривиальным тестам, не обладающим верификационной ценностью.

Таким образом, эффективность мутационного этапа определяется не только разнообразием применяемых операторов, но и степенью их адаптации к специфике архитектуры и контекста задач. В фаззинге RISC-V систем предпочтение отдается семантически осмысленным и направленным мутациям, которые обеспечивают как достижение архитектурной глубины, так и высокую вероятность обнаружения расхождений между моделями.

Вывод по теоретической части ГА: 

Рассмотренные этапы — инициализация популяции, оценка приспособленности, селекция, кроссовер и мутация — формируют основу эволюционного процесса, управляемого принципами отбора, наследования и вариативности. Каждый из этих компонентов может быть гибко адаптирован к специфике конкретной задачи, что делает генетические алгоритмы чрезвычайно гибкими и масштабируемыми.
 
С точки зрения инженерных приложений, ГА доказали свою эффективность в задачах, где требуется не просто точный результат, а быстрый поиск качественных решений в условиях ограниченной информации, высокой размерности и отсутствия аналитической модели. Эти свойства делают генетические алгоритмы особенно перспективными для применения в области автоматизированной верификации, включая фаззинг-тестирование аппаратных архитектур, где требуется исследование сложных состояний без полного перебо